# load libraries
library(rpart)         # to train decision trees
library(rpart.plot)    # to plot decision trees
library(randomForest)  # random forests
library(gbm)           # boosting
library(tidyverse)     # tidyverse
library(kableExtra)    # kable
setwd("~/Desktop/stat-471-fall-2021/kanter-rush-final")
# read in the training data
mental_health_train = read_csv("data/clean/mental_health_train.csv")
# read in the testing data
mental_health_test = read_csv("data/clean/mental_health_test.csv")
# Random Forests
set.seed(1)
rf_fit = randomForest(mentally_unhealthy_days ~ . -physically_unhealthy_days,
data = mental_health_train)
rf_fit$mtry
# tune random forests
set.seed(1)
mvalues = seq.int(1, 59, by = 5)
oob_errors = numeric(length(mvalues))
ntree = 100
for(idx in 1:length(mvalues)){
m = mvalues[idx]
rf_fit_tune = randomForest(mentally_unhealthy_days ~ . -physically_unhealthy_days,
mtry = m, data = mental_health_train)
oob_errors[idx] = rf_fit_tune$mse[ntree]
}
rf_cv = tibble(m = mvalues, oob_err = oob_errors) %>%
ggplot(aes(x = m, y = oob_err)) +
geom_line() + geom_point() +
scale_x_continuous(breaks = mvalues) +
theme_bw()
rf_cv
# load lasso fit object
load("results/lasso_fit.Rda")
lasso_fit$lambda.1se
lasso_fit$nzero[lasso_fit$lambda == lasso_fit$lambda.1se] # 49 features
# load libraries
library(glmnetUtils)
source("code/functions/plot_glmnet.R")
library(tidyverse)
library(kableExtra)
# read in the training data
mental_health_train = read_csv("data/clean/mental_health_train.csv")
# read in the test
mental_health_test = read_csv("data/clean/mental_health_test.csv")
# run lasso regression
set.seed(1)
lasso_fit = cv.glmnet(mentally_unhealthy_days ~. -physically_unhealthy_days,
alpha = 1,
nfolds = 10,
data = mental_health_train)
lasso_fit$nzero[lasso_fit$lambda == lasso_fit$lambda.1se] # 49 features
# save the lasso fit object
save(lasso_fit, file = "results/lasso_fit.Rda")
# load lasso fit object
load("results/lasso_fit.Rda")
lasso_fit$nzero[lasso_fit$lambda == lasso_fit$lambda.1se] # 49 features
lasso_fit$lambda.1se
# evaluate lasso mse
# test
predictions_test_lasso = predict(lasso_fit, newdata = mental_health_test,
s = "lambda.1se") %>% as.numeric()
mse_test_lasso = mean((predictions_test_lasso - mental_health_test$mentally_unhealthy_days)^2)
mse_test_lasso
# train
predictions_train_lasso = predict(lasso_fit, newdata = mental_health_train,
s = "lambda.1se") %>% as.numeric()
mse_train_lasso = mean((predictions_train_lasso - mental_health_train$mentally_unhealthy_days)^2)
mse_train_lasso
# load libraries
library(glmnetUtils)
source("code/functions/plot_glmnet.R")
library(tidyverse)
# read in the training data
mental_health_train = read_csv("data/clean/mental_health_train.csv")
# read in the test
mental_health_test = read_csv("data/clean/mental_health_test.csv")
# run ridge regression
set.seed(1)
ridge_fit = cv.glmnet(mentally_unhealthy_days ~ .- physically_unhealthy_days,
alpha = 0,
nfolds = 10,
data = mental_health_train)
ridge_fit$lambda.1se
# extract features selected by lasso and their coefficients
beta_hat_std = extract_std_coefs(ridge_fit, mental_health_train,
lambda = ridge_fit$lambda.1se)
# standard error - percent smokers
sd(mental_health_train$perc_smokers)
beta_hat_std %>%
filter(coefficient != 0) %>%
arrange(desc(abs(coefficient))) %>%
head(10)
# load lasso fit object
load("results/lasso_fit.Rda")
# extract features selected by lasso and their coefficients
beta_hat_std = extract_std_coefs(lasso_fit, mental_health_train)
beta_hat_std %>%
filter(coefficient != 0) %>%
arrange(desc(abs(coefficient))) %>%
head(10)
# load libraries
library(rpart)         # to train decision trees
library(rpart.plot)    # to plot decision trees
library(randomForest)  # random forests
library(gbm)           # boosting
library(tidyverse)     # tidyverse
library(kableExtra)    # kable
# read in the training data
mental_health_train = read_csv("data/clean/mental_health_train.csv")
# read in the testing data
mental_health_test = read_csv("data/clean/mental_health_test.csv")
# Random Forests
set.seed(1)
mvalues = seq.int(1, 60, by = 5)
oob_errors = numeric(length(mvalues))
ntree = 100
for(idx in 1:length(mvalues)){
m = mvalues[idx]
rf_fit_tune = randomForest(mentally_unhealthy_days ~ . -physically_unhealthy_days,
mtry = m, data = mental_health_train)
oob_errors[idx] = rf_fit_tune$mse[ntree]
}
